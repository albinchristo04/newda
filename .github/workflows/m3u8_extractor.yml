name: M3U8 URL and Events Extractor

on:
  schedule:
    # Run every 15 minutes
    - cron: '*/15 * * * *'
  
  # Allow manual triggering
  workflow_dispatch:
  
  # Run on push to main branch (for testing)
  push:
    branches: [ main ]

jobs:
  extract-m3u8:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      actions: read
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests
        
    - name: Run M3U8 extractor
      id: extraction
      run: |
        python m3u8_extractor.py
        echo "EXTRACTION_SUCCESS=true" >> $GITHUB_OUTPUT
      continue-on-error: true
        
    - name: List generated files
      run: |
        if [ -d "output" ]; then
          echo "Generated files:"
          ls -la output/
        else
          echo "No output directory found"
          exit 1
        fi
        
    - name: Upload extraction results
      if: steps.extraction.outputs.EXTRACTION_SUCCESS == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: m3u8-extraction-${{ github.run_number }}
        path: output/
        retention-days: 7
        if-no-files-found: error
        
    - name: Commit and push results (optional)
      if: steps.extraction.outputs.EXTRACTION_SUCCESS == 'true'
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        
        # Create a data directory if it doesn't exist
        mkdir -p data/extractions
        
        # Copy latest results to data directory with error handling
        if [ -d "output" ]; then
          cp output/*.json data/extractions/ 2>/dev/null || echo "No JSON files to copy"
          cp output/*.txt data/extractions/ 2>/dev/null || echo "No TXT files to copy"
        fi
        
        # Create a summary file with latest extraction info
        echo "# Latest M3U8 Extraction Results" > data/README.md
        echo "" >> data/README.md
        echo "Last updated: $(date -u)" >> data/README.md
        echo "" >> data/README.md
        echo "Workflow run: #${{ github.run_number }}" >> data/README.md
        echo "" >> data/README.md
        
        # Find the most recent URL file and add content
        LATEST_URLS=$(find output -name "urls_*.txt" -type f | head -1)
        if [ -f "$LATEST_URLS" ]; then
          echo "## Latest URLs (Sample):" >> data/README.md
          echo "\`\`\`" >> data/README.md
          head -20 "$LATEST_URLS" >> data/README.md
          echo "\`\`\`" >> data/README.md
        fi
        
        # Add and commit if there are changes
        git add data/
        if ! git diff --staged --quiet; then
          git commit -m "Update M3U8 extraction results - $(date -u) [Run #${{ github.run_number }}]"
          git push origin main
        else
          echo "No changes to commit"
        fi

  # Create a summary job that runs after extraction
  create-summary:
    needs: extract-m3u8
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - name: Download extraction artifacts
      uses: actions/download-artifact@v4
      with:
        name: m3u8-extraction-${{ github.run_number }}
        path: ./results
      continue-on-error: true
        
    - name: Create summary
      run: |
        echo "## M3U8 Extraction Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Extraction Time:** $(date -u)" >> $GITHUB_STEP_SUMMARY
        echo "**Workflow Run:** #${{ github.run_number }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -d "results" ] && [ "$(ls -A results)" ]; then
          echo "**Files Generated:**" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          ls -la results/ >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Count streams and events with error handling
          STREAMS="0"
          EVENTS="0"
          GROUPED_EVENTS="0"
          
          if command -v jq >/dev/null 2>&1; then
            PLAYLIST_JSON=$(find results -name "playlist_*.json" -type f | head -1)
            if [ -f "$PLAYLIST_JSON" ]; then
              STREAMS=$(jq '[.streams[]? | select(.type == "stream")] | length' "$PLAYLIST_JSON" 2>/dev/null || echo "0")
              GROUPED_EVENTS=$(jq '.grouped_events | length' "$PLAYLIST_JSON" 2>/dev/null || echo "0")
            fi
            
            EVENTS_JSON=$(find results -name "grouped_events_*.json" -type f | head -1)
            if [ -f "$EVENTS_JSON" ]; then
              EVENTS=$(jq '. | length' "$EVENTS_JSON" 2>/dev/null || echo "0")
            fi
          fi
          
          echo "**Statistics:**" >> $GITHUB_STEP_SUMMARY
          echo "- Streams found: $STREAMS" >> $GITHUB_STEP_SUMMARY
          echo "- Grouped events found: $GROUPED_EVENTS" >> $GITHUB_STEP_SUMMARY
          echo "- Total events: $EVENTS" >> $GITHUB_STEP_SUMMARY
          
          # Show sample URLs if available
          URLS_FILE=$(find results -name "urls_*.txt" -type f | head -1)
          if [ -f "$URLS_FILE" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Sample URLs:**" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
            head -10 "$URLS_FILE" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          fi
        else
          echo "⚠️ No extraction files found or extraction failed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Check the extraction job logs for details." >> $GITHUB_STEP_SUMMARY
        fi
